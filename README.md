

**CCKS2020评测任务一：新冠知识图谱构建与问答（四）新冠知识图谱问答评测**

****
#### 后续尝试提升点

1. 改进获取实体候选的方法（处理mention不在mention2ent文件中的情况）

#### 运行说明

##### 配置：

本实验基于python3(Anaconda3)，另外需要以下工具包：

1. pytorch-1.2.0
2. jieba-0.42.1
3. pkuseg

其他资源配置：

1. BERT中文词表和config文件已经保留，BERT中文模型参数需要下载。打开[链接](https://www.kaggle.com/soulmachine/pretrained-bert-models-for-pytorch?)，下载bert-base-chinese/pytorch_model.bin文件，并将其放至resource/bert-base-chinese目录下。
2. 下载知识图谱相关资源（链接：https://pan.baidu.com/s/1mQXgm7BtdQin3oLUoPqNXQ  提取码：cs35），将pkubase-complete2.txt和pkubase-mention2ent.txt放至resource目录下。
3. 下载数据集（链接：https://pan.baidu.com/s/1IqCfmkmAQTBz5K37Sv-7Kw 提取码：81ek），将task1-4_train_2020.txt和task1-4_valid_2020.questions放至data目录下。

##### 运行：

配置完运行环境后，开始执行程序。

1. 执行以下代码清理PKUBASE与收集mention2entity映射文件。

   ```shell
   bash resource_prepare.sh
   ```

2. 使用virtuoso搭建PKUBASE的SPARQL查询端口（[搭建流程](https://blog.csdn.net/wtgwtg_/article/details/107963602)），搭建完成后修改utils/configure.py中的endpoint。

3. 准备数据与训练（使用RTX2080TI）。

   ```shell
   
   ```

4. 获取验证集和测试集的答案。

   ```
   python test.py
   ```

#### 训练记录

验证集只发布了问题，不包含SPARQL，所以本文从训练集中每十个取一个（即400个问题）作为实际验证集，剩余3600个问题作为实际训练集。

clean pkubase 0.5H

get mention2ent  1H

entity and pair prepare 0.5H

qg prepare 0.5H

| component | 3      | k=5    | 10     | 15     |        |
| --------- | ------ | ------ | ------ | ------ | ------ |
| ner       |        |        |        |        | 0.8263 |
| entity    | 0.8933 | 0.9087 | 0.9187 | 0.9208 |        |
| pair      | 0.8462 | 0.8833 | 0.9050 | 0.9083 |        |
| qg        |        |        |        |        | 0.9725 |

| entity\pair | 3                    | 5(p,r,f1)            | 10                   | 15                   |
| ----------- | -------------------- | -------------------- | -------------------- | -------------------- |
| -1          | 0.6731/0.7031/0.6733 | 0.6818/0.7077/0.6812 | 0.6575/0.6765/0.6507 | 0.6586/0.6768/0.6536 |
| 0 (ner)     | 0.6451/0.6597/0.6466 | 0.6433/0.6546/0.6417 | 0.6360/0.6467/0.6315 | 0.6308/0.6427/0.6276 |
| 3           | 0.7106/0.7442/0.7118 |                      |                      |                      |
| 5           |                      | 0.6945/0.7168/0.6901 |                      |                      |
| 10          |                      |                      | 0.6529/0.6703/0.6385 |                      |
| 15          |                      |                      |                      | 0.6634/0.6880/0.6608 |

| 训练样本            | 官方发布训练集 |
| ------------------- | -------------- |
| 平均实体候选数      | 45.89          |
| 含正确实体比例      | 0.9335         |
| 实体-关系对平均数量 | 207.71         |
| 含正确实体关系对率  | 0.9297         |
| 查询图平均数量      | 200左右        |

##### **old：**

 **filter+rank**

| 数据集         | filter | rank   | precision | recall | F1     |
| -------------- | ------ | ------ | --------- | ------ | ------ |
| 实际验证集     | 0.8963 | 0.7325 | 0.7871    | 0.8100 | 0.7906 |
| 官方发布验证集 |        |        | 0.8115    | 0.8332 | 0.8134 |

|                      | 官方发布训练集 |
| -------------------- | -------------- |
| 平均实体候选数       | 38.89          |
| 含正确实体比例       | 0.9384         |
| 实体-关系对平均数量  | 652.31         |
| 含正确实体关系对率   | 0.9334         |
| K=10，查询图平均数量 | 330+           |
| K=10，含正确查询图率 | 0.86左右       |

#### 数据集统计

| **问题类型** | **训练集** | **验证集** | **测试集** |
| ------------ | ---------- | ---------- | ---------- |
| 单实体单跳   | 2324       |            |            |
| 单实体多跳   | 738        |            |            |
| 多实体单跳   | 777        |            |            |
| 其他         | 161        |            |            |
| 总数         | 4000       | 1529       |            |

